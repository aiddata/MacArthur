sea_csv <- paste(mDir, "analysis_data/merged/sea_merge.csv", sep="")
mDir= "/home/aid_data/Desktop/GitRepo/MacArthur/"
sea_csv <- paste(mDir, "analysis_data/merged/sea_merge.csv", sep="")
sea_csv
sea_dta <- read.csv(sea_csv)
head(sea_dta)
install.packages(jsonlite)
install.packages("jsonlite")
sea_csv <- paste(mDir, "analysis_data/merged/sea_merge.csv", sep="")
sea_json <- paste(mDir, "analysis_data/merged/sea_merge.json", sep="")
sea_dta <- read.csv(sea_csv)
sea_vars <- fromJSON(file=sea_json)
sea_vars <- fromJSON(txt=sea_json)
library(jsonlite)
sea_vars <- fromJSON(txt=sea_json)
View(sea_vars)
colnames(sea_vars)
names(sea_vars)
sea_vars["dist_to_all_rivers"]
sea_vars["dist_to_all_rivers"]$data_mini
sea_vars$dist_to_all_rivers$data_mini
?matrix
vars <- fromJSON(txt=sea_json)
vars[1]
vars[1]$\data_name
vars[1]$data_name
vars[1]["data_name"]
vars[1]
vars[1][1]
vars[1][2]
vars[1,]
vars[,1]
vars[1]
vars[1]
vars[1]$file_mask
vars[1]$dist_to_all_rivers$file_mask
nrow(vars)
colnames(vars)
names(vars)
names(vars)[1]
vars[names(vars)[1]]
vars[names(vars)[1]][1]
vars[names(vars)[1]]$names(vars)[[1]]
vars[names(vars)[1]]$names(vars)
vars[names(vars)[1]]$names(vars)[1]
vars[names(vars)[1]]
flatten(vars)
vars$data[[1]]
vars$data_name
vars$data_name[[1]]
varMatrix <- matrix(data=NA, nrow=length(names(vars)), ncol=2)
for (i in 1:length(names(vars)))
{
cur_var <- names(vars)[i]
print(cur_var)
#varMatrix[i] <- c(vars[i]$data_mini, vars[i]$data_name)
}
var
vars
for (i in 1:length(names(vars)))
{
cur_var <- names(vars)[i]
short_name <-eval(parse(text= paste("var$",cur_var,"$data_mini", sep="")))
varMatrix[i] <- c(short_name, cur_var)
}
var$dist_to_all_rivers$data_mini
var$dist_to_all_rivers["data_mini"]
var$dist_to_all_rivers["data_mini",]
var
vars
for (i in 1:length(names(vars)))
{
cur_var <- names(vars)[i]
short_name <-eval(parse(text= paste("vars$",cur_var,"$data_mini", sep="")))
varMatrix[i] <- c(short_name, cur_var)
}
warnings()
varMatrix
varMatrix <- matrix(data=NA, nrow=length(names(vars)), ncol=2)
for (i in 1:length(names(vars)))
{
cur_var <- names(vars)[i]
short_name <-eval(parse(text= paste("vars$",cur_var,"$data_mini", sep="")))
varMatrix[i,] <- c(short_name, cur_var)
}
varMatrix
print(xtable(varMatrix))
library(xtable)
isntall.packages("xtable")
install.packages("xtable")
print(xtable(varMatrix))
library(xtable)
print(xtable(varMatrix))
print(xtable(varMatrix), caption=var_caption, label="Variable Table",
size="footnotesize",
include.rownames=FALSE,
include.colnames=FALSE,
capiton.placement="bottom",
hline.after=NULL,
add.to.row=list(pos = list(-1,
nrow(narMatrix)),
command=c(paste("\\toprule \n",
"Short Name & Long Name \\\\\n", "\\midrule \n", "\\bottomrule \n"))))
print(xtable(varMatrix), caption=var_caption, label="Variable Table",
size="footnotesize",
include.rownames=FALSE,
include.colnames=TRUE,
capiton.placement="bottom",
hline.after=NULL)
print(xtable(varMatrix, caption=var_caption, label="Variable Table"),
size="footnotesize",
include.rownames=FALSE,
include.colnames=TRUE,
capiton.placement="bottom",
hline.after=NULL)
var_caption <- paste0("\\textbf{Table 1} Table caption here....")
print(xtable(varMatrix, caption=var_caption, label="Variable Table"),
size="footnotesize",
include.rownames=FALSE,
include.colnames=TRUE,
capiton.placement="bottom",
hline.after=NULL)
colname(varMatrix)
colnames(varMatrix)
var_caption <- paste0("\\textbf{Table 1} Table caption here....")
colnames(varMatrix) <- c("Long", "Short")
print(xtable(varMatrix, caption=var_caption, label="Variable Table"),
size="footnotesize",
include.rownames=FALSE,
include.colnames=TRUE,
capiton.placement="bottom",
hline.after=NULL)
library(sp)
library(jsonlite)
library(xtable)
#Load in SEA data
csv <- paste(mDir, "analysis_data/merged/sea_merge.csv", sep="")
json <- paste(mDir, "analysis_data/merged/sea_merge.json", sep="")
dta <- read.csv(sea_csv)
vars <- fromJSON(txt=sea_json)
print(xtable(varMatrix, caption=var_caption, label="Variable_Table"),
size="footnotesize",
include.rownames=FALSE,
include.colnames=TRUE,
capiton.placement="bottom",
hline.after=NULL)
head(dta)
csv <- paste(mDir, "analysis_data/merged/sea_merge.csv", sep="")
json <- paste(mDir, "analysis_data/merged/sea_merge.json", sep="")
dta <- read.csv(csv)
csv <- paste(mDir, "analysis_data/merged/sea_merge.csv", sep="")
mDir= "/home/aid_data/Desktop/GitRepo/MacArthur/"
csv <- paste(mDir, "analysis_data/merged/sea_merge.csv", sep="")
json <- paste(mDir, "analysis_data/merged/sea_merge.json", sep="")
dta <- read.csv(csv)
head(dta)
length(unique(dta$OBJECTID))
head(csv)
head(vars)
head(da)
head(dta)
unique(dta$NAME_0)
print(xtable(varMatrix, caption=var_caption, label="Variable_Table"),
size="footnotesize",
include.rownames=FALSE,
include.colnames=TRUE,
capiton.placement="bottom"
)
library(xtable)
print(xtable(varMatrix, caption=var_caption, label="Variable_Table"),
size="footnotesize",
include.rownames=FALSE,
include.colnames=TRUE,
capiton.placement="bottom"
)
varMatrix <- matrix(data=NA, nrow=length(names(vars)), ncol=2)
for (i in 1:length(names(vars)))
{
cur_var <- names(vars)[i]
short_name <-eval(parse(text= paste("vars$",cur_var,"$data_mini", sep="")))
varMatrix[i,] <- c(short_name, cur_var)
}
var_caption <- paste0("Variables used in this analysis.")
colnames(varMatrix) <- c("Short Name", "Long Name")
vars <- fromJSON(txt=json)
library(jsonlite)
vars <- fromJSON(txt=json)
varMatrix <- matrix(data=NA, nrow=length(names(vars)), ncol=2)
for (i in 1:length(names(vars)))
{
cur_var <- names(vars)[i]
short_name <-eval(parse(text= paste("vars$",cur_var,"$data_mini", sep="")))
varMatrix[i,] <- c(short_name, cur_var)
}
var_caption <- paste0("Variables used in this analysis.")
colnames(varMatrix) <- c("Short Name", "Long Name")
print(xtable(varMatrix, caption=var_caption, label="Variable_Table"),
size="footnotesize",
include.rownames=FALSE,
include.colnames=TRUE,
capiton.placement="bottom"
)
install.packages("papeR")
latex.table.cont(dta)
library(papeR)
latex.table.cont(dta)
install.packages(stargazer)
install.packages("stargazer")
stargazer(dta)
library(stargazer)
stargazer(dta)
names(dta2)
names(dta)
names(dta[6])
test <- dta[c(6,23:297)]
names(test)
t2 <- aggregate(test, by="OBJECTID")
t2 <- aggregate(test, by="OBJECTID", FUN=mean)
t2 <- aggregate(test, by=list(OBJECTID"", FUN=mean)
t2 <- aggregate(test, by=list(OBJECTID), FUN=mean)
t2 <- aggregate(test, by=list("OBJECTID"), FUN=mean)
t2 <- aggregate(test, by=list("OBJECTID"), FUN=mean, na.rm=TRUE)
install.packages("data.table")
head(dta2)
head(dta)
names(dta)
summary(dta$tc00_e)
colnames(dta)
?hist
mDir= getwd()
mDir= getwd()
getwd()
%tools>global options>sweave>weave rnw files using: knitr
%sudo apt-get install texlive
%sudo apt-get install texlive-latex-extra
%sudo apt-get install texlive-bibtex-extra
\documentclass{article}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage[backend=bibtex, style=nature, citestyle=authoryear]{biblatex}
\usepackage[table]{xcolor}
\bibliography{WBVFM_IntroPar}
\newenvironment{knitrout}{}{}  %just a dummy environment
\makeatletter
\newcommand\gobblepars{%
\@ifnextchar\par%
{\expandafter\gobblepars\@gobble}%
{}}
\makeatother
\title{Descriptives: SEA and MacArthur}
\begin{document}
%\SweaveOpts{concordance=TRUE}
\begin{knitrout}
\maketitle
\tableofcontents
getwd()
library(RCurl)
ftp_url <- "ftp://reu:reudata@ftp.aiddata.wm.edu/REU/MacArthur/analysis_data"
filenames = getURL(ftp_url, ftp.use.epsv = FALSE, dirlistonly = TRUE)
filenames
getURL("ftp://reu:reudata@ftp.aiddata.wm.edu/REU/MacArthur/analysis_data", ftp.use.epsv = FALSE, dirlistonly = TRUE)
getURL("ftp://reu:reudata@ftp.aiddata.wm.edu/REU/MacArthur/analysis_data/", ftp.use.epsv = FALSE, dirlistonly = TRUE)
files <- strsplit(filenames, "\r*\n")[[1]]
files
ftp_url <- "ftp://reu:reudata@ftp.aiddata.wm.edu/REU/MacArthur/analysis_data/"
filenames = getURL(ftp_url, ftp.use.epsv = FALSE, dirlistonly = TRUE)
files <- strsplit(filenames, "\r*\n")[[1]]
files
ftp_url <- "ftp://reu:reudata@ftp.aiddata.wm.edu/REU/MacArthur/analysis_data/"
ftp_url <- "ftp://reu:reudata@ftp.aiddata.wm.edu/REU/MacArthur/analysis_data/"
filenames = getURL(ftp_url, ftp.use.epsv = FALSE, dirlistonly = TRUE)
filenames = getURL(ftp_url, ftp.use.epsv = FALSE, dirlistonly = TRUE)
ftp_url <- "ftp://reu:reudata@ftp.aiddata.wm.edu/REU/MacArthur/analysis_data/"
filenames = getURL(ftp_url, ftp.use.epsv = FALSE, dirlistonly = TRUE)
files <- strsplit(filenames, "\r*\n")[[1]]
files
files[0]
files[1]
files[2]
files <- lapply(as.numeric, strsplit(filenames, "\r*\n")[[1]])
file_times <- as.numeric(files)
file_times
order(file_times)
file_times[order(file_times)]
file_times[order(-file_times)]
ftp_url <- "ftp://reu:reudata@ftp.aiddata.wm.edu/REU/MacArthur/analysis_data/"
filenames = getURL(ftp_url, ftp.use.epsv = FALSE, dirlistonly = TRUE)
files_char <- strsplit(filenames, "\r*\n")[[1]]
files_int <- as.numeric(files_char)
file_order <- as.character(files_int[order(-files_int)])
file_order
file_active = file_order[1]
file_active
ftp_url <- "ftp://reu:reudata@ftp.aiddata.wm.edu/REU/MacArthur/analysis_data/"
dir_names = getURL(ftp_url, ftp.use.epsv = FALSE, dirlistonly = TRUE)
dirs_char <- strsplit(dir_names, "\r*\n")[[1]]
dirs_int <- as.numeric(dirs_char)
dirs_order <- as.character(dirs_int[order(-dirs_int)])
dir_active = dirs_order[1]
# make new dir
active_dir_path = paste(mDir, "/analysis_data/", dir_active, sep='')
dir.create(active_dir_path, showWarnings = FALSE)
# get files
active_url <- paste(ftp_url, dir_active, '/', sep='')
file_str = getURL(active_url, ftp.use.epsv = FALSE, dirlistonly = TRUE)
file_names <- strsplit(file_str, "\r*\n")[[1]]
mDir = getwd()
# find latest data
ftp_url <- "ftp://reu:reudata@ftp.aiddata.wm.edu/REU/MacArthur/analysis_data/"
dir_names = getURL(ftp_url, ftp.use.epsv = FALSE, dirlistonly = TRUE)
dirs_char <- strsplit(dir_names, "\r*\n")[[1]]
dirs_int <- as.numeric(dirs_char)
dirs_order <- as.character(dirs_int[order(-dirs_int)])
dir_active = dirs_order[1]
# make new dir
active_dir_path = paste(mDir, "/analysis_data/", dir_active, sep='')
dir.create(active_dir_path, showWarnings = FALSE)
# get files
active_url <- paste(ftp_url, dir_active, '/', sep='')
file_str = getURL(active_url, ftp.use.epsv = FALSE, dirlistonly = TRUE)
file_names <- strsplit(file_str, "\r*\n")[[1]]
for (i in 1:length(file_names)) {
print(i)
dst_file <- paste(active_dir_path, '/', file_names[[i]], sep="")
src_file <- paste(ftp_url, "/", file_names[[i]], sep="")
print(src_file)
download.file(src_file, destfile=dst_file, method="libcurl")
#     #copy the file without the revision history tags for use in the script.
#     name <- paste(strsplit(files[i], "_")[[1]][1],".",strsplit(strsplit(files[i], "_")[[1]][2], "[.]")[[1]][2], sep="")
#     new_name <- paste(mDir, "/analysis_data/", name, sep="")
#     file.copy(cur_file, new_name, overwrite=TRUE)
}
src_file <- paste(active_url, "/", file_names[[i]], sep="")
print(src_file)
file.exists(active_dir_path)
